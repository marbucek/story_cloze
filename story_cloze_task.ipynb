{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads stories from the validation file. Each sentence has two possible outcomes: either the 5th or 6th sentence. The label (1 or 2) indicates which sentence contains the correct ending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InputStoryid</th>\n",
       "      <th>InputSentence1</th>\n",
       "      <th>InputSentence2</th>\n",
       "      <th>InputSentence3</th>\n",
       "      <th>InputSentence4</th>\n",
       "      <th>RandomFifthSentenceQuiz1</th>\n",
       "      <th>RandomFifthSentenceQuiz2</th>\n",
       "      <th>AnswerRightEnding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138d5bfb-05cc-41e3-bf2c-fa85ebad14e2</td>\n",
       "      <td>Rick grew up in a troubled household.</td>\n",
       "      <td>He never found good support in family, and tur...</td>\n",
       "      <td>It wasn't long before Rick got shot in a robbery.</td>\n",
       "      <td>The incident caused him to turn a new leaf.</td>\n",
       "      <td>He is happy now.</td>\n",
       "      <td>He joined a gang.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bff9f820-9605-4875-b9af-fe6f14d04256</td>\n",
       "      <td>Laverne needs to prepare something for her fri...</td>\n",
       "      <td>She decides to bake a batch of brownies.</td>\n",
       "      <td>She chooses a recipe and follows it closely.</td>\n",
       "      <td>Laverne tests one of the brownies to make sure...</td>\n",
       "      <td>The brownies are so delicious Laverne eats two...</td>\n",
       "      <td>Laverne doesn't go to her friend's party.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e8f628d5-9f97-40ed-8611-fc0e774673c4</td>\n",
       "      <td>Sarah had been dreaming of visiting Europe for...</td>\n",
       "      <td>She had finally saved enough for the trip.</td>\n",
       "      <td>She landed in Spain and traveled east across t...</td>\n",
       "      <td>She didn't like how different everything was.</td>\n",
       "      <td>Sarah then decided to move to Europe.</td>\n",
       "      <td>Sarah decided that she preferred her home over...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f5226bfe-9f26-4377-b05f-3d9568dbdec1</td>\n",
       "      <td>Gina was worried the cookie dough in the tube ...</td>\n",
       "      <td>She was very happy to find she was wrong.</td>\n",
       "      <td>The cookies from the tube were as good as from...</td>\n",
       "      <td>Gina intended to only eat 2 cookies and save t...</td>\n",
       "      <td>Gina liked the cookies so much she ate them al...</td>\n",
       "      <td>Gina gave the cookies away at her church.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69ac9b05-b956-402f-9fff-1f926ef9176b</td>\n",
       "      <td>It was  my final performance in marching band.</td>\n",
       "      <td>I was playing the snare drum in the band.</td>\n",
       "      <td>We played Thriller and Radar Love.</td>\n",
       "      <td>The performance was flawless.</td>\n",
       "      <td>I was very proud of my performance.</td>\n",
       "      <td>I was very ashamed of my performance.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           InputStoryid  \\\n",
       "0  138d5bfb-05cc-41e3-bf2c-fa85ebad14e2   \n",
       "1  bff9f820-9605-4875-b9af-fe6f14d04256   \n",
       "2  e8f628d5-9f97-40ed-8611-fc0e774673c4   \n",
       "3  f5226bfe-9f26-4377-b05f-3d9568dbdec1   \n",
       "4  69ac9b05-b956-402f-9fff-1f926ef9176b   \n",
       "\n",
       "                                      InputSentence1  \\\n",
       "0              Rick grew up in a troubled household.   \n",
       "1  Laverne needs to prepare something for her fri...   \n",
       "2  Sarah had been dreaming of visiting Europe for...   \n",
       "3  Gina was worried the cookie dough in the tube ...   \n",
       "4     It was  my final performance in marching band.   \n",
       "\n",
       "                                      InputSentence2  \\\n",
       "0  He never found good support in family, and tur...   \n",
       "1           She decides to bake a batch of brownies.   \n",
       "2         She had finally saved enough for the trip.   \n",
       "3          She was very happy to find she was wrong.   \n",
       "4          I was playing the snare drum in the band.   \n",
       "\n",
       "                                      InputSentence3  \\\n",
       "0  It wasn't long before Rick got shot in a robbery.   \n",
       "1       She chooses a recipe and follows it closely.   \n",
       "2  She landed in Spain and traveled east across t...   \n",
       "3  The cookies from the tube were as good as from...   \n",
       "4                 We played Thriller and Radar Love.   \n",
       "\n",
       "                                      InputSentence4  \\\n",
       "0        The incident caused him to turn a new leaf.   \n",
       "1  Laverne tests one of the brownies to make sure...   \n",
       "2      She didn't like how different everything was.   \n",
       "3  Gina intended to only eat 2 cookies and save t...   \n",
       "4                      The performance was flawless.   \n",
       "\n",
       "                            RandomFifthSentenceQuiz1  \\\n",
       "0                                   He is happy now.   \n",
       "1  The brownies are so delicious Laverne eats two...   \n",
       "2              Sarah then decided to move to Europe.   \n",
       "3  Gina liked the cookies so much she ate them al...   \n",
       "4                I was very proud of my performance.   \n",
       "\n",
       "                            RandomFifthSentenceQuiz2  AnswerRightEnding  \n",
       "0                                  He joined a gang.                  1  \n",
       "1          Laverne doesn't go to her friend's party.                  1  \n",
       "2  Sarah decided that she preferred her home over...                  2  \n",
       "3          Gina gave the cookies away at her church.                  1  \n",
       "4              I was very ashamed of my performance.                  1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/data_val.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vld set contains both true and fake stories, roc set only the true stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def read_data(file, data_type = 'val'):\n",
    "    data = pd.read_csv(file)\n",
    "    stories = []; labels = []\n",
    "    for _, row in data.iterrows():\n",
    "        story = {}\n",
    "        if data_type == 'roc':\n",
    "            story['ctx'] = [nltk.word_tokenize(sentence.lower()) for sentence in list(row[2:6])]\n",
    "            story['ends'] = nltk.word_tokenize(row[6].lower())\n",
    "            stories.append((story,))\n",
    "            labels.append(+1)\n",
    "        if data_type == 'val':\n",
    "            story['ctx'] = [nltk.word_tokenize(sentence.lower()) for sentence in list(row[1:5])]\n",
    "            story['ends'] = [nltk.word_tokenize(sentence.lower()) for sentence in list(row[5:7])]\n",
    "            stories.append(story.copy())\n",
    "            labels.append(row[7])\n",
    "    return stories, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories, labels = read_data('data/data_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "model = models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dim_embedding = 300\n",
    "\n",
    "np.random.seed(10)\n",
    "UKN = np.random.uniform(low=-0.25, high=0.25, size=dim_embedding)\n",
    "\n",
    "def w2v(token):\n",
    "    try:\n",
    "        return model[token]\n",
    "    except:\n",
    "        return UKN\n",
    "\n",
    "def centroid(tokens):\n",
    "        if len(tokens) == 0:\n",
    "            return np.zeros(shape = [dim_embedding,])\n",
    "        else:\n",
    "#             for token in tokens:\n",
    "#                 print(token, w2v(token)[0:10])\n",
    "            return np.mean([w2v(token) for token in tokens], axis = 0)\n",
    "    \n",
    "def cosine(vec1, vec2):\n",
    "    if np.sum(vec1**2)*np.sum(vec2**2) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sum(vec1*vec2)/np.sqrt(np.sum(vec1**2)*np.sum(vec2**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centroid feature: concatenates the centroid of the context with the centroid of the ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_feature(story):\n",
    "    ctr_context = np.mean([centroid(sentence) for sentence in story['ctx']], axis = 0)\n",
    "    return np.concatenate([ctr_context, centroid(story['end'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average similarity: computes cosine distance between the centroid vector of the ending and vectors of the words in the context. Similarity scores of the words with top_N highest scores are returned as the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sim(story, top_N = [1,2,3,5]):\n",
    "    ctx_embeddings = [w2v(token) for token in list(set(sum(story['ctx'],[])))]\n",
    "    words_similarity = sorted([cosine(embedding, centroid(list(set(story['end'])))) for embedding in ctx_embeddings], reverse = True)\n",
    "    top_similarities = np.asarray([words_similarity[id] for id in top_N])\n",
    "    return top_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max similarity: for each word in the context, chooses the most similar word from the ending and takes the average of all best word pair similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sim(story):\n",
    "    words_similarity = []\n",
    "    for token in list(set(sum(story['ctx'],[]))):\n",
    "        words_similarity.append(\n",
    "                    np.max([cosine(w2v(token),w2v(token_end)) for token_end in story['end']])\n",
    "                    )\n",
    "    return [np.mean(words_similarity)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all combinations (POS1, POS2) in the context and ending computes centroid similarity between all words of type POS1 in the context and all words of type POS2 in the ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_sim(story, POS = ['VBZ','VBN','VBP','VBG','VBD','VB','RBS','RBR','RB','POS','NN','NNS','JJS','JJR','JJ']):\n",
    "    POS_context = nltk.pos_tag(sum(story['ctx'],[]))\n",
    "    POS_end = nltk.pos_tag(story['end'])\n",
    "\n",
    "    pos_sim = []\n",
    "    for pos1 in POS:\n",
    "        for pos2 in POS:\n",
    "            ctr_context = centroid([token for token, pos in POS_context if pos == pos1])\n",
    "            ctr_end = centroid([token for token, pos in POS_end if pos == pos2])\n",
    "            pos_sim.append(cosine(ctr_context, ctr_end))\n",
    "\n",
    "    return np.array(pos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(stories):\n",
    "    \n",
    "    X = []\n",
    "    for item in stories:\n",
    "        story = {}; features = []\n",
    "        for end in item['ends']:\n",
    "            story['ctx'] = item['ctx']\n",
    "            story['end'] = end\n",
    "            X_story = np.concatenate([feature(story) \n",
    "                                       for feature in [centroid_feature, average_sim, max_sim, pos_sim]])\n",
    "            features.append(X_story)\n",
    "        X.append(np.stack(features))\n",
    "    return np.stack(X)\n",
    "\n",
    "def get_y(labels):\n",
    "    y = []\n",
    "    for label in labels:\n",
    "        y.append(np.array([1,0])) if label == 1 else y.append(np.array([0,1]))\n",
    "    return np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(clf, X):\n",
    "    labels = []\n",
    "    for x in X:\n",
    "        prob_true = clf.predict_proba(x)[:,1]\n",
    "        labels.append(1) if np.argmax(prob_true) == 0 else labels.append(2)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_features(stories)\n",
    "y = get_y(labels)\n",
    "stories_tst, labels_tst = read_data('data/data_test.csv')\n",
    "Xts = get_features(stories_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7140566541956174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X.reshape([2*X.shape[0],-1]), y.reshape(-1))\n",
    "labels_pred = predict_labels(lg, Xts)\n",
    "print(f'Accuracy = {accuracy_score(labels_tst, labels_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
