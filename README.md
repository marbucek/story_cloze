Before the advancements in AI, many task that require understanding of stories were easy to solve for humans but notoriously difficult for computers. In order to create an evaluation scheme for language models, cognitive researchers recently collected a database of simple 5-sentence long true and fake stories - the so called [Story Cloze Test](https://arxiv.org/abs/1604.01696). Stories were written by the workers of the [Amazon Mechanical Turk](https://www.mturk.com) and each story comes with two alternative (true and fake) endings. The language model is then tested on its ability to identify the correct ending.

Various neural-network based language models reach accuracies on this task around 90% (the [BERT](https://arxiv.org/pdf/1905.07504.pdf) or [MANN](https://www.aclweb.org/anthology/C18-1149) model), however just after publishing the dataset, simple machine learning techniques like logistic regression performed even better than neural networks (this was actually only three years ago and given the speed in AI research it is of course no longer true). In this post we describe a simple logistic regression model classifying stories based on hand-designed language features that achieves decent accuracy exceeding 72%. The idea is based on [this](https://arxiv.org/abs/1703.04330) paper by Mihaylov et. al.

Later we show how to add more features and increase the model accuracy to more than 74% using the [Skip-Thought](https://arxiv.org/abs/1506.06726) vectors.

The code with comments and instructions can be found in the [jupyter notebook](./story_cloze_task.ipynb).
